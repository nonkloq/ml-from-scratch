# Machine Learning Algorithms From Scratch

Implementations of several machine learning algorithms from scratch. The implementations are done in Python by only using basic libraries like NumPy, Pandas, and Matplotlib...
 
## Notebooks

The following notebooks are included:

### Supervised Learning

- [Linear Regression](linear%20regression.ipynb)
- [Locally Weighted Regression (LWR)](LWR.ipynb)

- [Linear Classification](linear%20classification.ipynb) ( SVM is not implemented from scratch)

- [Multilayered Perceptron (Neural Network)](https://github.com/nonkloq/nn_dqn-from-scratch/blob/main/nn-mlp_from_scratch.ipynb)
- [Multinomial & Gaussian Naive Bayes](Multinomial_and_GaussianNP.ipynb)

- [K-Nearest Neighbors (KNN) for classification (iris dataset)](KNN_for_iris.ipynb) (clone from linear classification)


### Unsupervised Learning

- [Unsupervised Learning](unsupervised%20learners.ipynb)  (contains K-means, KNN and EM for GMM)

- [K-Means and Expectation-Maximization for Gaussian Mixture Model (Viz)](EM_for_GMM_and_Kmeans.ipynb) (clone from unsupervised learners, just check this out)

### Inductive Learning

- [Candidate Elimination Algorithm (CEL)](CEL.ipynb)

### Ensemble Learning

- [Decision Tree and Random Forest](trees&forest.ipynb)


## Usage

The code is provided in Jupyter Notebook format (.ipynb), which you can either view directly on GitHub or download and run on your local machine. Each notebook contains clear implementations of the algorithms, along with the relevant formulas and pseudo code for that algorithm. For better understanding of the algorithms, check out the specific notebook of interest.

## References

- Pattern Recognition and Machine Learning by Christopher Bishop
- Machine Learning: An Algorithmic Perspective, Second Edition by Stephen Marsland
