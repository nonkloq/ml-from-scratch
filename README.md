# Machine Learning Algorithms From Scratch

Implementations of several machine learning algorithms from scratch. The implementations are done in Python by only using basic libraries like NumPy, Pandas, and Matplotlib...
 
## Notebooks

The following notebooks are included:

### Supervised Learning

- [Linear Regression](linear%20regression.ipynb)
- [Locally Weighted Regression (LWR)](LWR.ipynb)

- [Linear Classification](linear%20classification.ipynb) ( SVM is not implemented from scratch)

- [Multilayered Perceptron (Neural Network)](https://github.com/nonkloq/nn_dqn-from-scratch/blob/main/nn-mlp_from_scratch.ipynb)
- [Multinomial & Gaussian Naive Bayes](Multinomial_and_GaussianNP.ipynb)

- [K-Nearest Neighbors (KNN) for classification (iris dataset)](KNN_for_iris.ipynb) (clone from linear classification)


### Unsupervised Learning

- [Unsupervised Learning](unsupervised%20learners.ipynb)  (contains K-means and EM for GMM)

- [K-Means and Expectation-Maximization for Gaussian Mixture Model (Viz)](EM_for_GMM_and_Kmeans.ipynb) (clone from unsupervised learners, just check it out)

### Inductive Learning

- [Candidate Elimination Algorithm (CEL)](CEL.ipynb)

### Ensemble Learning

- [Decision Tree and Random Forest](trees&forest.ipynb)


## Usage
The code is available in Jupyter Notebook format (.ipynb). You can view the notebooks directly on GitHub or download them and run them locally on your machine. 

## References

- Pattern Recognition and Machine Learning by Christopher Bishop
- Machine Learning: An Algorithmic Perspective, Second Edition by Stephen Marsland
